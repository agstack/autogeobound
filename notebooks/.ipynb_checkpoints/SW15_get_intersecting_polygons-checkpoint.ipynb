{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "import shapefile\n",
    "import json\n",
    "from json import dumps\n",
    "import fiona\n",
    "from pyproj import Proj#, transform\n",
    "import pyproj\n",
    "\n",
    "import shapely\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import shape\n",
    "from functools import partial\n",
    "from shapely.ops import transform\n",
    "from shapely.strtree import STRtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally shp2geo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(shape_file, readCSV):\n",
    "    \"\"\"Read the coordinate of the bounding boxes and constructs and R-Tree data structure\n",
    "\n",
    "    Args:\n",
    "      shape_file : polygons\n",
    "      readCSV: pandas dataframe containing bounding boxes\n",
    "\n",
    "    Returns:\n",
    "    dict, r-tree: dict of bounding boxes for each image id and r-tree\n",
    "    \"\"\"\n",
    "    shapes = fiona.open(shape_file)\n",
    "    if len(shapes.crs) != 0:\n",
    "        destination = Proj(shapes.crs)\n",
    "    else:\n",
    "        destination = Proj('+init=EPSG:4326')\n",
    "    original = Proj('+init=EPSG:4326')\n",
    "\n",
    "    grid = dict()\n",
    "    keys = ['max_lat', 'max_lon', 'min_lat', 'min_lon']\n",
    "    poly_list = []\n",
    "    \n",
    "    for index, row in readCSV.iterrows():\n",
    "        if index not in grid:\n",
    "            grid[index] = dict()\n",
    "        grid[index]['image_id'] = row['image_id']\n",
    "        grid[index]['max_lat'] = float(row['max_lat'])\n",
    "        grid[index]['max_lon'] = float(row['max_lon'])\n",
    "        grid[index]['min_lat'] = float(row['min_lat'])\n",
    "        grid[index]['min_lon'] = float(row['min_lon'])\n",
    "\n",
    "        grid[index]['poly'] = shapely.geometry.box(\n",
    "            grid[index]['min_lon'], grid[index]['min_lat'], grid[index]['max_lon'], grid[index]['max_lat'])\n",
    "        \n",
    "        # project boxes from WSG 84 to parcel projection\n",
    "        project = partial(pyproj.transform, original, destination)\n",
    "        grid[index]['poly'] = transform(project, grid[index]['poly'])\n",
    "\n",
    "        # populating r-tree\n",
    "        poly_obj = grid[index]['poly']\n",
    "        poly_obj.name = grid[index]['image_id'] # useful for retrival in search phase\n",
    "        poly_list.append(poly_obj)\n",
    "        \n",
    "    tree = STRtree(poly_list) # constructing R-Tree\n",
    "    return grid, tree\n",
    "\n",
    "def listit(t):\n",
    "    # convert to appropriate list type \n",
    "    return list(map(listit, t)) if isinstance(t, (list, tuple)) else t\n",
    "\n",
    "\n",
    "def check_polygon_in_bounds(poly, tree):\n",
    "    \"\"\"\n",
    "    find image corrspinding to the existance of a field in the list of \n",
    "    image bounding boxes\n",
    "\n",
    "    Args:\n",
    "      poly (polygon): field\n",
    "      tree (r-tree): r-tree of images\n",
    "\n",
    "    Returns:\n",
    "      List: List of intersecting images with a field\n",
    "    \"\"\"\n",
    "    results = tree.query(poly)\n",
    "    return results\n",
    "\n",
    "\n",
    "def field_imageId_list(polys, count_parcels):\n",
    "    \"\"\"\n",
    "    extract name of the intersecting polygons\n",
    "\n",
    "    Args:\n",
    "      polys (polygons): intersecting fields\n",
    "      count_parcels (dict): the sanity check summary of # of fields in image ids  \n",
    "    Returns:\n",
    "      list: list of the image ids\n",
    "    \"\"\"\n",
    "    list_image_ids = []\n",
    "    for element in polys:\n",
    "        list_image_ids.append(element.name)\n",
    "        count_parcels[element.name] += 1\n",
    "    return list_image_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find intersecting polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_shp_to_json(shape_file, grid, tree, output_json='../data/planet/france/sherrie10k/test_json'):\n",
    "    \"\"\"\n",
    "    find intersecting polygons in the list of available images and save the GeoJSON\n",
    "\n",
    "    Args:\n",
    "      shape_file (polygons): fields\n",
    "      grid (dict): image bounding boxes \n",
    "      tree (r-tre): r-tree of images\n",
    "      output_json (str): output path of json file\n",
    "    \"\"\"\n",
    "    # coordinate transformation\n",
    "    reader = shapefile.Reader(shape_file)\n",
    "    shapes = fiona.open(shape_file)\n",
    "    if len(shapes.crs) != 0:\n",
    "        original = Proj(shapes.crs)\n",
    "    else:\n",
    "        original = Proj('+init=EPSG:4326')\n",
    "#     print(fiona.open(shape_file).crs)\n",
    "\n",
    "    # list of properties of features\n",
    "    fields = reader.fields[1:]\n",
    "    field_names = [field[0] for field in fields]\n",
    "    field_names.append('image_id')\n",
    "\n",
    "    buffer = []\n",
    "    # sanity check counters\n",
    "    count_parcels = defaultdict(int)\n",
    "#     index = 0\n",
    "    counter_method1 = 0\n",
    "    counter_method2 = 0\n",
    "    num_matched = 0\n",
    "    failed_projection = 0\n",
    "  \n",
    "    # loop through the polygon fields\n",
    "    for sr in tqdm(reader.iterShapeRecords(), total=9517878):\n",
    "#         if index % 100000 == 0:\n",
    "#             print('Parsed ', index)\n",
    "#         index += 1\n",
    "        geom = sr.shape.__geo_interface__\n",
    "        shp_geom = shape(geom)\n",
    "        intersect = check_polygon_in_bounds(shp_geom, tree)\n",
    "#         print(intersect)\n",
    "        if len(intersect) != 0:\n",
    "            num_matched += len(intersect)\n",
    "#             print(\"Matched:\", str(index))\n",
    "#             print(\"Number matched:\", num_matched)\n",
    "      \n",
    "            id_list = field_imageId_list(intersect, count_parcels)\n",
    "            sr.record.append(id_list)\n",
    "            atr = dict(zip(field_names, sr.record))\n",
    "            \n",
    "            geom['coordinates'] = listit(geom['coordinates'])\n",
    "            try: # protection at polygons that fail at projection\n",
    "                if len(geom['coordinates']) == 1: # for single polygon\n",
    "                    counter_method1 += 1\n",
    "                    x, y = zip(*geom['coordinates'][0])\n",
    "                    lat, long = original(x, y, inverse=True) # coordinate transformation\n",
    "                    geom['coordinates'] = [listit(list(zip(lat, long)))]\n",
    "                else: # for multipolygons\n",
    "                    counter_method2 += 1\n",
    "                    for index_coord in range(0, len(geom['coordinates'])):\n",
    "                        for counter in range(0,len(geom['coordinates'][index_coord])):\n",
    "                            x, y = geom['coordinates'][index_coord][counter]\n",
    "                            lat, long = original(x, y, inverse=True) # coordinate transformation\n",
    "                            geom['coordinates'][index_coord][counter] = [lat, long] #(long, lat)\n",
    "            except:\n",
    "                failed_projection =+ 1\n",
    "#                 print(geom['coordinates'])\n",
    "            buffer.append(dict(type=\"Feature\", geometry=geom, properties=atr))\n",
    "            \n",
    "#             if num_matched > 10:\n",
    "#                 break\n",
    "      \n",
    "      \n",
    "    # write the GeoJSON file\n",
    "    output_json_interval = output_json + str(num_matched) + '.json'\n",
    "    print(\"saving json\")\n",
    "    with open(output_json_interval, 'w') as geojson:\n",
    "        geojson.write(dumps({\"type\": \"FeatureCollection\", \"features\": buffer}, indent=2) + \"\\n\")\n",
    "        geojson.close()\n",
    "        print('saved', output_json_interval)\n",
    "    \n",
    "    # print summary\n",
    "    print('method one count:', counter_method1)\n",
    "    print('method two count:', counter_method2)\n",
    "    print(\"Number matched:\", num_matched)\n",
    "    print('failed count', failed_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = fiona.open(shape_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID_PARCEL',\n",
       " 'SURF_PARC',\n",
       " 'CODE_CULTU',\n",
       " 'CODE_GROUP',\n",
       " 'CULTURE_D1',\n",
       " 'CULTURE_D2']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test.schema['properties'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'MultiPolygon', 'coordinates': [[[(701200.320100002, 6883238.830900002), (700676.8660000041, 6882785.608600002), (700657.6099999994, 6882831.337000001), (700652.1803000048, 6882844.3105), (700646.9530000016, 6882853.198800001), (700627.3748000041, 6882878.875500001), (700617.5866999999, 6882893.216300003), (700613.4576999992, 6882901.178100001), (700585.1190000027, 6882964.341000002), (700568.450000003, 6883002.176000003), (700553.0282000005, 6883039.002), (700539.0053000003, 6883078.2927), (700540.7251000032, 6883084.113500003), (700639.8117000014, 6883181.4804), (700742.3322999999, 6883282.026700001), (701020.0553000048, 6883553.359200001), (701148.2096000016, 6883518.824800003), (701147.2836000025, 6883498.9810000025), (701143.9200000018, 6883446.650000002), (701143.1825000048, 6883398.5715), (701146.2990000024, 6883375.501900002), (701154.2087000012, 6883351.177100003), (701166.5234000012, 6883320.895800002), (701164.6138000041, 6883310.729600001), (701174.5357000008, 6883287.975400001), (701184.1930000037, 6883263.501400001), (701194.644100003, 6883242.8638), (701200.320100002, 6883238.830900002)]]]}\n"
     ]
    }
   ],
   "source": [
    "for t in test:\n",
    "    print(t['geometry'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_dir = '../data/planet/france/sherrie10k/'\n",
    "# csv_file = os.path.join(base_dir, 'bbox10k.csv')\n",
    "# csv_file = os.path.join(base_dir, 'bbox10k_1250px.csv')\n",
    "csv_file = os.path.join(base_dir, 'bbox10k_2500px.csv')\n",
    "\n",
    "shape_file = '../data/parcels/france/RPG_2-0__SHP_LAMB93_FR-2018_2018-01-15/RPG/1_DONNEES_LIVRAISON_2018/RPG_2-0_SHP_LAMB93_FR-2018/PARCELLES_GRAPHIQUES.shp'\n",
    "# TODO: update shape file to 2019\n",
    "\n",
    "if os.path.exists(os.path.join(base_dir, 'json_polys')) == False:\n",
    "    os.makedirs(os.path.join(base_dir, 'json_polys'))\n",
    "\n",
    "for start in np.arange(0, 1500, 250): # np.arange(1500, 10000, 250):\n",
    "    end = start + 250\n",
    "    images_df = pd.read_csv(csv_file).iloc[start:end]\n",
    "    images_df['image_id'] = images_df['image_id'].astype(str).str.zfill(5)\n",
    "    grid, tree = read_csv(shape_file, images_df)\n",
    "    \n",
    "    dump_shp_to_json(shape_file, grid, tree, \n",
    "                     '../data/planet/france/sherrie10k/json_polys/bbox10k_2500px_{}_'.format(int(start/250)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019 Geopackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = fiona.open(shape_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proj = Proj(test.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in test:\n",
    "    if len(t['geometry']['coordinates']) > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = t['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(871071.9519999996, 6895244.015000001),\n",
       " (871071.9827999994, 6895244.0273),\n",
       " (871072.9772000015, 6895241.6697),\n",
       " (871072.9785000011, 6895241.669200003),\n",
       " (871548.8317000046, 6895434.682700001),\n",
       " (871725.5075000003, 6895505.657300003),\n",
       " (871892.441399999, 6895569.984700002),\n",
       " (871904.3320000023, 6895558.030000001),\n",
       " (871910.7366999984, 6895547.213300001),\n",
       " (871917.0866999999, 6895528.4278),\n",
       " (871918.2650000006, 6895513.297000002),\n",
       " (871916.9420000017, 6895504.0370000005),\n",
       " (871907.4294000044, 6895482.125600003),\n",
       " (871902.5249000043, 6895477.249300003),\n",
       " (871884.4105999991, 6895459.239100002),\n",
       " (871802.3350000009, 6895392.929000001),\n",
       " (871766.6579999998, 6895360.632000003),\n",
       " (871729.6621000022, 6895339.944900002),\n",
       " (871421.6810000017, 6895157.777000003),\n",
       " (871371.2897000015, 6895130.869100001),\n",
       " (871371.2390000001, 6895130.842100002),\n",
       " (871370.7206000015, 6895131.712300003),\n",
       " (871156.5509000048, 6895047.279900003),\n",
       " (871156.5323000029, 6895047.323700003),\n",
       " (871155.5854000002, 6895046.995300002),\n",
       " (871155.0212000012, 6895048.324300002),\n",
       " (871071.9519999996, 6895244.015000001)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geom['coordinates'][index_coord][counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(871071.9827999994, 6895244.0273),\n",
       "  (871857.5275000036, 6895558.577600002),\n",
       "  (871890.6110000014, 6895571.825000003),\n",
       "  (871892.2334000021, 6895570.193800002),\n",
       "  (871889.9606000036, 6895571.5645),\n",
       "  (871071.9827999994, 6895244.0273)]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geom['coordinates'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_coord in range(0, len(geom['coordinates'])):\n",
    "    for counter in range(0,len(geom['coordinates'][index_coord][0])):\n",
    "        x, y = geom['coordinates'][index_coord][0][counter]\n",
    "        lat, long = test_proj(x, y, inverse=True) # coordinate transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = zip(*geom['coordinates'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_shp_to_json(shape_file, grid, tree, output_json='../data/planet/france/sherrie10k/test_json'):\n",
    "    \"\"\"\n",
    "    find intersecting polygons in the list of available images and save the GeoJSON\n",
    "\n",
    "    Args:\n",
    "      shape_file (polygons): fields\n",
    "      grid (dict): image bounding boxes \n",
    "      tree (r-tre): r-tree of images\n",
    "      output_json (str): output path of json file\n",
    "    \"\"\"\n",
    "    # coordinate transformation\n",
    "    shapes = fiona.open(shape_file)\n",
    "    if len(shapes.crs) != 0:\n",
    "        original = Proj(shapes.crs)\n",
    "    else:\n",
    "        original = Proj('+init=EPSG:4326')\n",
    "\n",
    "    # list of properties of features\n",
    "#     field_names = shapes.schema['properties'].keys()\n",
    "#     field_names.append('image_id')\n",
    "    \n",
    "    # sanity check counters\n",
    "    buffer = []\n",
    "    count_parcels = defaultdict(int)\n",
    "    index = 0\n",
    "    counter_method1 = 0\n",
    "    counter_method2 = 0\n",
    "    num_matched = 0\n",
    "    failed_projection = 0\n",
    "  \n",
    "    # loop through the polygon fields\n",
    "    for sr in tqdm(shapes, total=9517878):\n",
    "#         if index % 100000 == 0:\n",
    "#             print('Parsed ', index)\n",
    "#         index += 1\n",
    "        geom = sr['geometry']\n",
    "        shp_geom = shape(geom)\n",
    "        intersect = check_polygon_in_bounds(shp_geom, tree)\n",
    "#         print(intersect)\n",
    "        if len(intersect) != 0:\n",
    "            num_matched += len(intersect)\n",
    "#             print(\"Matched:\", str(index))\n",
    "#             print(\"Number matched:\", num_matched)\n",
    "      \n",
    "            id_list = field_imageId_list(intersect, count_parcels)\n",
    "            atr = dict(sr['properties'])\n",
    "            atr['image_id'] = id_list\n",
    "#             sr.record.append(id_list)\n",
    "#             atr = dict(zip(field_names, sr.record))\n",
    "            \n",
    "            geom['coordinates'] = listit(geom['coordinates'])\n",
    "            try: # protection at polygons that fail at projection\n",
    "                if len(geom['coordinates']) == 1: # for single polygon\n",
    "                    counter_method1 += 1\n",
    "                    x, y = zip(*geom['coordinates'][0][0])\n",
    "                    lat, long = original(x, y, inverse=True) # coordinate transformation\n",
    "                    geom['coordinates'] = [listit(list(zip(lat, long)))]\n",
    "                else: # for multipolygons\n",
    "                    counter_method2 += 1\n",
    "                    for index_coord in range(0, len(geom['coordinates'])):\n",
    "                        for counter in range(0,len(geom['coordinates'][index_coord][0])):\n",
    "                            x, y = geom['coordinates'][index_coord][0][counter]\n",
    "                            lat, long = original(x, y, inverse=True) # coordinate transformation\n",
    "                            geom['coordinates'][index_coord][counter] = [lat, long] #(long, lat)\n",
    "            except:\n",
    "                failed_projection += 1\n",
    "#                 print(geom['coordinates'])\n",
    "            buffer.append(dict(type=\"Feature\", geometry=geom, properties=atr))\n",
    "            \n",
    "            # for debugging\n",
    "#             if num_matched > 10:\n",
    "#                 break\n",
    "      \n",
    "      \n",
    "    # write the GeoJSON file\n",
    "    output_json_interval = output_json + str(num_matched) + '.json'\n",
    "    print(\"saving json\")\n",
    "    with open(output_json_interval, 'w') as geojson:\n",
    "        geojson.write(dumps({\"type\": \"FeatureCollection\", \"features\": buffer}, indent=2) + \"\\n\")\n",
    "        geojson.close()\n",
    "        print('saved', output_json_interval)\n",
    "    \n",
    "    # print summary\n",
    "    print('method one count:', counter_method1)\n",
    "    print('method two count:', counter_method2)\n",
    "    print(\"Number matched:\", num_matched)\n",
    "    print('failed count', failed_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [16:18, 9816.81it/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_0_23365.json\n",
      "method one count: 23327\n",
      "method two count: 0\n",
      "Number matched: 23365\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [16:31, 9690.12it/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_1_24138.json\n",
      "method one count: 24127\n",
      "method two count: 0\n",
      "Number matched: 24138\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [16:26, 9734.33it/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2_24287.json\n",
      "method one count: 24264\n",
      "method two count: 0\n",
      "Number matched: 24287\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [16:24, 9754.87it/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_3_23178.json\n",
      "method one count: 23169\n",
      "method two count: 0\n",
      "Number matched: 23178\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 477805/9517878 [00:47<18:24, 8185.56it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 63%|██████▎   | 5983555/9517878 [10:07<05:27, 10788.11it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "9604463it [16:20, 9796.65it/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_4_23120.json\n",
      "method one count: 23072\n",
      "method two count: 0\n",
      "Number matched: 23120\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1785552/9517878 [03:01<17:05, 7537.50it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 50%|████▉     | 4729537/9517878 [07:52<07:46, 10274.39it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 82%|████████▏ | 7769850/9517878 [13:01<02:47, 10407.57it/s]"
     ]
    }
   ],
   "source": [
    "base_dir = '../data/planet/france/sherrie10k/'\n",
    "csv_file = os.path.join(base_dir, 'bbox10k.csv')\n",
    "# csv_file = os.path.join(base_dir, 'bbox10k_1250px.csv')\n",
    "# csv_file = os.path.join(base_dir, 'bbox10k_2500px.csv')\n",
    "\n",
    "# shape_file = '../data/parcels/france/RPG_2-0__SHP_LAMB93_FR-2018_2018-01-15/RPG/1_DONNEES_LIVRAISON_2018/RPG_2-0_SHP_LAMB93_FR-2018/PARCELLES_GRAPHIQUES.shp'\n",
    "# TODO: update shape file to 2019\n",
    "shape_file = '../data/parcels/france/RPG_2-0_GPKG_LAMB93_FR-2019/RPG/1_DONNEES_LIVRAISON_2019/RPG_2-0_GPKG_LAMB93_FR-2019/PARCELLES_GRAPHIQUES.gpkg'\n",
    "\n",
    "if os.path.exists(os.path.join(base_dir, 'json_polys')) == False:\n",
    "    os.makedirs(os.path.join(base_dir, 'json_polys'))\n",
    "\n",
    "# 300px and 1250px images\n",
    "images_per_file = 1000\n",
    "for start in np.arange(0, 10000, images_per_file):\n",
    "    end = start + images_per_file\n",
    "    images_df = pd.read_csv(csv_file).iloc[start:end]\n",
    "    images_df['image_id'] = images_df['image_id'].astype(str).str.zfill(5)\n",
    "    grid, tree = read_csv(shape_file, images_df)\n",
    "\n",
    "    dump_shp_to_json(shape_file, grid, tree, \n",
    "                     '../data/planet/france/sherrie10k/json_polys_2019/bbox10k_{}_'.format(int(start/images_per_file)))\n",
    "\n",
    "# 2500px images\n",
    "# images_per_file = 250 \n",
    "# for start in np.arange(250, 10000, images_per_file):\n",
    "#     end = start + images_per_file\n",
    "#     images_df = pd.read_csv(csv_file).iloc[start:end]\n",
    "#     images_df['image_id'] = images_df['image_id'].astype(str).str.zfill(5)\n",
    "#     grid, tree = read_csv(shape_file, images_df)\n",
    "    \n",
    "#     dump_shp_to_json(shape_file, grid, tree, \n",
    "#                      '../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_{}_'.format(int(start/images_per_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 6741942/9517878 [12:46<05:03, 9149.60it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "9604463it [18:27, 8672.22it/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_1250px_2_292629.json\n",
      "method one count: 286678\n",
      "method two count: 0\n",
      "Number matched: 292629\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2349602/9517878 [04:19<13:51, 8617.18it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 82%|████████▏ | 7767145/9517878 [14:19<03:23, 8599.82it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 42%|████▏     | 4006520/9517878 [07:28<09:33, 9603.30it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 95%|█████████▍| 9012342/9517878 [17:07<00:52, 9705.70it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 82%|████████▏ | 7829994/9517878 [14:35<05:15, 5351.85it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 31%|███       | 2957769/9517878 [05:28<13:52, 7876.62it/s] "
     ]
    }
   ],
   "source": [
    "base_dir = '../data/planet/france/sherrie10k/'\n",
    "# csv_file = os.path.join(base_dir, 'bbox10k.csv')\n",
    "csv_file = os.path.join(base_dir, 'bbox10k_1250px.csv')\n",
    "# csv_file = os.path.join(base_dir, 'bbox10k_2500px.csv')\n",
    "\n",
    "# shape_file = '../data/parcels/france/RPG_2-0__SHP_LAMB93_FR-2018_2018-01-15/RPG/1_DONNEES_LIVRAISON_2018/RPG_2-0_SHP_LAMB93_FR-2018/PARCELLES_GRAPHIQUES.shp'\n",
    "# TODO: update shape file to 2019\n",
    "shape_file = '../data/parcels/france/RPG_2-0_GPKG_LAMB93_FR-2019/RPG/1_DONNEES_LIVRAISON_2019/RPG_2-0_GPKG_LAMB93_FR-2019/PARCELLES_GRAPHIQUES.gpkg'\n",
    "\n",
    "if os.path.exists(os.path.join(base_dir, 'json_polys')) == False:\n",
    "    os.makedirs(os.path.join(base_dir, 'json_polys'))\n",
    "\n",
    "# 300px and 1250px images\n",
    "images_per_file = 1000\n",
    "for start in np.arange(0, 10000, images_per_file):\n",
    "    end = start + images_per_file\n",
    "    images_df = pd.read_csv(csv_file).iloc[start:end]\n",
    "    images_df['image_id'] = images_df['image_id'].astype(str).str.zfill(5)\n",
    "    grid, tree = read_csv(shape_file, images_df)\n",
    "\n",
    "#     dump_shp_to_json(shape_file, grid, tree, \n",
    "#                      '../data/planet/france/sherrie10k/json_polys_2019/bbox10k_{}_'.format(int(start/images_per_file)))\n",
    "    dump_shp_to_json(shape_file, grid, tree, \n",
    "                     '../data/planet/france/sherrie10k/json_polys_2019/bbox10k_1250px_{}_'.format(int(start/images_per_file)))\n",
    "\n",
    "# 2500px images\n",
    "# images_per_file = 250 \n",
    "# for start in np.arange(250, 10000, images_per_file):\n",
    "#     end = start + images_per_file\n",
    "#     images_df = pd.read_csv(csv_file).iloc[start:end]\n",
    "#     images_df['image_id'] = images_df['image_id'].astype(str).str.zfill(5)\n",
    "#     grid, tree = read_csv(shape_file, images_df)\n",
    "    \n",
    "#     dump_shp_to_json(shape_file, grid, tree, \n",
    "#                      '../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_{}_'.format(int(start/images_per_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [12:46, 12526.03it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2172/9517878 [00:00<07:18, 21711.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_6_288684.json\n",
      "method one count: 284965\n",
      "method two count: 0\n",
      "Number matched: 288684\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 2945285/9517878 [03:38<09:41, 11301.72it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 68%|██████▊   | 6484918/9517878 [08:00<03:07, 16198.39it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "9604463it [10:33, 15169.94it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1492/9517878 [00:00<10:37, 14917.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_9_272310.json\n",
      "method one count: 267356\n",
      "method two count: 0\n",
      "Number matched: 272310\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3096410/9517878 [03:10<05:51, 18273.33it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  0%|          | 0/9517878 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_10_271939.json\n",
      "method one count: 269159\n",
      "method two count: 1\n",
      "Number matched: 271939\n",
      "failed count 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:44, 16430.59it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2348/9517878 [00:00<06:45, 23479.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_11_261721.json\n",
      "method one count: 255460\n",
      "method two count: 0\n",
      "Number matched: 261721\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [10:30, 15223.88it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_12_269393.json\n",
      "method one count: 266073\n",
      "method two count: 0\n",
      "Number matched: 269393\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:49, 16299.33it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2321/9517878 [00:00<06:50, 23203.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_13_253779.json\n",
      "method one count: 249295\n",
      "method two count: 0\n",
      "Number matched: 253779\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:51, 16225.55it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2276/9517878 [00:00<06:58, 22758.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_14_292750.json\n",
      "method one count: 286249\n",
      "method two count: 1\n",
      "Number matched: 292750\n",
      "failed count 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [10:29, 15249.54it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2125/9517878 [00:00<07:27, 21249.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_15_259118.json\n",
      "method one count: 257527\n",
      "method two count: 1\n",
      "Number matched: 259118\n",
      "failed count 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [10:00, 15999.45it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_16_295360.json\n",
      "method one count: 291977\n",
      "method two count: 1\n",
      "Number matched: 295360\n",
      "failed count 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:53, 16174.41it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_17_255654.json\n",
      "method one count: 251875\n",
      "method two count: 0\n",
      "Number matched: 255654\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [10:23, 15408.76it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9517878 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_18_257334.json\n",
      "method one count: 256236\n",
      "method two count: 1\n",
      "Number matched: 257334\n",
      "failed count 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:52, 16222.31it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2303/9517878 [00:00<06:53, 23020.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_19_276848.json\n",
      "method one count: 272195\n",
      "method two count: 2\n",
      "Number matched: 276848\n",
      "failed count 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:50, 16269.99it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_20_262002.json\n",
      "method one count: 256788\n",
      "method two count: 0\n",
      "Number matched: 262002\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [10:28, 15270.75it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2061/9517878 [00:00<07:41, 20607.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_21_272577.json\n",
      "method one count: 269022\n",
      "method two count: 0\n",
      "Number matched: 272577\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:56, 16096.87it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2158/9517878 [00:00<07:21, 21563.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_22_284713.json\n",
      "method one count: 282092\n",
      "method two count: 2\n",
      "Number matched: 284713\n",
      "failed count 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:52, 16218.90it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2286/9517878 [00:00<06:56, 22857.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_23_275841.json\n",
      "method one count: 271285\n",
      "method two count: 1\n",
      "Number matched: 275841\n",
      "failed count 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [10:33, 15160.30it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_24_274699.json\n",
      "method one count: 271857\n",
      "method two count: 1\n",
      "Number matched: 274699\n",
      "failed count 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:51, 16245.19it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_25_268769.json\n",
      "method one count: 262144\n",
      "method two count: 0\n",
      "Number matched: 268769\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:47, 16358.23it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9517878 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_26_278306.json\n",
      "method one count: 274252\n",
      "method two count: 0\n",
      "Number matched: 278306\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [10:33, 15149.22it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_27_270542.json\n",
      "method one count: 268005\n",
      "method two count: 0\n",
      "Number matched: 270542\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:53, 16189.66it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9517878 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_28_267738.json\n",
      "method one count: 261177\n",
      "method two count: 0\n",
      "Number matched: 267738\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:52, 16218.67it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_29_285515.json\n",
      "method one count: 284850\n",
      "method two count: 0\n",
      "Number matched: 285515\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [10:33, 15170.82it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_30_264797.json\n",
      "method one count: 257894\n",
      "method two count: 0\n",
      "Number matched: 264797\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [10:07, 15810.22it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_31_272505.json\n",
      "method one count: 271017\n",
      "method two count: 0\n",
      "Number matched: 272505\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:58, 16039.08it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1561/9517878 [00:00<10:09, 15603.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_32_279244.json\n",
      "method one count: 277374\n",
      "method two count: 0\n",
      "Number matched: 279244\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [10:28, 15272.13it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2346/9517878 [00:00<06:45, 23441.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_33_264697.json\n",
      "method one count: 260328\n",
      "method two count: 0\n",
      "Number matched: 264697\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:54, 16168.58it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_34_264940.json\n",
      "method one count: 261742\n",
      "method two count: 0\n",
      "Number matched: 264940\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:49, 16291.53it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2329/9517878 [00:00<06:48, 23281.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_35_273013.json\n",
      "method one count: 270895\n",
      "method two count: 1\n",
      "Number matched: 273013\n",
      "failed count 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [10:36, 15078.71it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_36_282654.json\n",
      "method one count: 281245\n",
      "method two count: 0\n",
      "Number matched: 282654\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:49, 16295.75it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9517878 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_37_258864.json\n",
      "method one count: 256744\n",
      "method two count: 0\n",
      "Number matched: 258864\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [09:49, 16294.13it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_38_269585.json\n",
      "method one count: 265951\n",
      "method two count: 0\n",
      "Number matched: 269585\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9604463it [10:30, 15241.59it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_39_256261.json\n",
      "method one count: 251184\n",
      "method two count: 0\n",
      "Number matched: 256261\n",
      "failed count 0\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../data/planet/france/sherrie10k/'\n",
    "# csv_file = os.path.join(base_dir, 'bbox10k.csv')\n",
    "# csv_file = os.path.join(base_dir, 'bbox10k_1250px.csv')\n",
    "csv_file = os.path.join(base_dir, 'bbox10k_2500px.csv')\n",
    "\n",
    "# shape_file = '../data/parcels/france/RPG_2-0__SHP_LAMB93_FR-2018_2018-01-15/RPG/1_DONNEES_LIVRAISON_2018/RPG_2-0_SHP_LAMB93_FR-2018/PARCELLES_GRAPHIQUES.shp'\n",
    "# TODO: update shape file to 2019\n",
    "shape_file = '../data/parcels/france/RPG_2-0_GPKG_LAMB93_FR-2019/RPG/1_DONNEES_LIVRAISON_2019/RPG_2-0_GPKG_LAMB93_FR-2019/PARCELLES_GRAPHIQUES.gpkg'\n",
    "\n",
    "if os.path.exists(os.path.join(base_dir, 'json_polys')) == False:\n",
    "    os.makedirs(os.path.join(base_dir, 'json_polys'))\n",
    "\n",
    "# 300px and 1250px images\n",
    "# images_per_file = 1000\n",
    "# for start in np.arange(0, 10000, images_per_file):\n",
    "#     end = start + images_per_file\n",
    "#     images_df = pd.read_csv(csv_file).iloc[start:end]\n",
    "#     images_df['image_id'] = images_df['image_id'].astype(str).str.zfill(5)\n",
    "#     grid, tree = read_csv(shape_file, images_df)\n",
    "\n",
    "#     dump_shp_to_json(shape_file, grid, tree, \n",
    "#                      '../data/planet/france/sherrie10k/json_polys_2019/bbox10k_{}_'.format(int(start/images_per_file)))\n",
    "#     dump_shp_to_json(shape_file, grid, tree, \n",
    "#                      '../data/planet/france/sherrie10k/json_polys_2019/bbox10k_1250px_{}_'.format(int(start/images_per_file)))\n",
    "\n",
    "# 2500px images\n",
    "images_per_file = 250 \n",
    "for start in np.arange(0, 10000, images_per_file):\n",
    "    end = start + images_per_file\n",
    "    images_df = pd.read_csv(csv_file).iloc[start:end]\n",
    "    images_df['image_id'] = images_df['image_id'].astype(str).str.zfill(5)\n",
    "    grid, tree = read_csv(shape_file, images_df)\n",
    "    \n",
    "    dump_shp_to_json(shape_file, grid, tree, \n",
    "                     '../data/planet/france/sherrie10k/json_polys_2019/bbox10k_2500px_{}_'.format(int(start/images_per_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defined a new dump_shp_to_json function for india because the projection wasn't working...\n",
    "# the parcels should already be in LAT, LON and don't need to be reprojected\n",
    "# but somehow the inverse projection was messing things up\n",
    "# TODO: fix this in a general way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_shp_to_json(shape_file, grid, tree, output_json='../data/planet/france/sherrie10k/test_json'):\n",
    "    \"\"\"\n",
    "    find intersecting polygons in the list of available images and save the GeoJSON\n",
    "\n",
    "    Args:\n",
    "      shape_file (polygons): fields\n",
    "      grid (dict): image bounding boxes \n",
    "      tree (r-tre): r-tree of images\n",
    "      output_json (str): output path of json file\n",
    "    \"\"\"\n",
    "    # coordinate transformation\n",
    "    reader = shapefile.Reader(shape_file)\n",
    "    shapes = fiona.open(shape_file)\n",
    "    if len(shapes.crs) != 0:\n",
    "        original = Proj(shapes.crs)\n",
    "    else:\n",
    "        original = Proj('+init=EPSG:4326')\n",
    "#     print(fiona.open(shape_file).crs)\n",
    "\n",
    "    # list of properties of features\n",
    "    fields = reader.fields[1:]\n",
    "    field_names = [field[0] for field in fields]\n",
    "    field_names.append('image_id')\n",
    "\n",
    "    buffer = []\n",
    "    # sanity check counters\n",
    "    count_parcels = defaultdict(int)\n",
    "#     index = 0\n",
    "    counter_method1 = 0\n",
    "    counter_method2 = 0\n",
    "    num_matched = 0\n",
    "    failed_projection = 0\n",
    "  \n",
    "    # loop through the polygon fields\n",
    "    for sr in tqdm(reader.iterShapeRecords(), total=9517878):\n",
    "#         if index % 100000 == 0:\n",
    "#             print('Parsed ', index)\n",
    "#         index += 1\n",
    "        geom = sr.shape.__geo_interface__\n",
    "        shp_geom = shape(geom)\n",
    "        intersect = check_polygon_in_bounds(shp_geom, tree)\n",
    "#         print(intersect)\n",
    "        if len(intersect) != 0:\n",
    "            num_matched += len(intersect)\n",
    "#             print(\"Matched:\", str(index))\n",
    "#             print(\"Number matched:\", num_matched)\n",
    "      \n",
    "            id_list = field_imageId_list(intersect, count_parcels)\n",
    "            sr.record.append(id_list)\n",
    "            atr = dict(zip(field_names, sr.record))\n",
    "            \n",
    "            geom['coordinates'] = listit(geom['coordinates'])\n",
    "#             print(geom)\n",
    "            try: # protection at polygons that fail at projection\n",
    "                if len(geom['coordinates']) == 1: # for single polygon\n",
    "                    counter_method1 += 1\n",
    "                    x, y = zip(*geom['coordinates'][0])\n",
    "                    lat,long = x, y\n",
    "#                     lat, long = original(x, y, inverse=True) # coordinate transformation\n",
    "#                     print(x,y)\n",
    "#                     print(lat,long)\n",
    "                    geom['coordinates'] = [listit(list(zip(lat, long)))]\n",
    "                else: # for multipolygons\n",
    "                    counter_method2 += 1\n",
    "                    for index_coord in range(0, len(geom['coordinates'])):\n",
    "                        for counter in range(0,len(geom['coordinates'][index_coord])):\n",
    "                            x, y = geom['coordinates'][index_coord][counter]\n",
    "                            lat, long = original(x, y, inverse=True) # coordinate transformation\n",
    "                            geom['coordinates'][index_coord][counter] = [lat, long] #(long, lat)\n",
    "            except:\n",
    "                failed_projection =+ 1\n",
    "#                 print(geom['coordinates'])\n",
    "            buffer.append(dict(type=\"Feature\", geometry=geom, properties=atr))\n",
    "            \n",
    "#             if num_matched > 10:\n",
    "#                 break\n",
    "      \n",
    "      \n",
    "    # write the GeoJSON file\n",
    "    output_json_interval = output_json + str(num_matched) + '.json'\n",
    "    print(\"saving json\")\n",
    "    with open(output_json_interval, 'w') as geojson:\n",
    "        geojson.write(dumps({\"type\": \"FeatureCollection\", \"features\": buffer}, indent=2) + \"\\n\")\n",
    "        geojson.close()\n",
    "        print('saved', output_json_interval)\n",
    "    \n",
    "    # print summary\n",
    "    print('method one count:', counter_method1)\n",
    "    print('method two count:', counter_method2)\n",
    "    print(\"Number matched:\", num_matched)\n",
    "    print('failed count', failed_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1638/9517878 [00:00<16:47, 9447.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/india/json_polys/bbox1000_labeled1600.json\n",
      "method one count: 1600\n",
      "method two count: 0\n",
      "Number matched: 1600\n",
      "failed count 0\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../data/planet/india/'\n",
    "csv_file = os.path.join(base_dir, 'bbox1000.csv')\n",
    "\n",
    "shape_file = '../mount/data/india_parcels/india_parcels_with_area.shp'\n",
    "\n",
    "if os.path.exists(os.path.join(base_dir, 'json_polys')) == False:\n",
    "    os.makedirs(os.path.join(base_dir, 'json_polys'))\n",
    "\n",
    "# for start in np.arange(0, 1500, 250): # np.arange(1500, 10000, 250):\n",
    "#     end = start + 250\n",
    "#     images_df = pd.read_csv(csv_file).iloc[start:end]\n",
    "\n",
    "images_df = pd.read_csv(csv_file)\n",
    "images_df['image_id'] = images_df['image_id'].astype(str).str.zfill(5)\n",
    "images_df = images_df[images_df['image_id'].isin(['00064', '00126'])]\n",
    "\n",
    "grid, tree = read_csv(shape_file, images_df)\n",
    "\n",
    "dump_shp_to_json(shape_file, grid, tree, \n",
    "                 '../data/planet/india/json_polys/bbox1000_labeled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GeoWiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 266/9517878 [00:00<19:01, 8339.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/india/geowiki/json_polys/geowiki_labeled259.json\n",
      "method one count: 259\n",
      "method two count: 0\n",
      "Number matched: 259\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../data/planet/india/geowiki/'\n",
    "csv_file = os.path.join(base_dir, 'geowiki_maharashtra.csv')\n",
    "\n",
    "shape_file = '../mount/data/india_parcels/india_geowiki_parcels_with_area.shp'\n",
    "\n",
    "if os.path.exists(os.path.join(base_dir, 'json_polys')) == False:\n",
    "    os.makedirs(os.path.join(base_dir, 'json_polys'))\n",
    "\n",
    "images_df = pd.read_csv(csv_file)\n",
    "images_df = images_df[images_df['image_id'].isin([960228])]\n",
    "\n",
    "grid, tree = read_csv(shape_file, images_df)\n",
    "\n",
    "dump_shp_to_json(shape_file, grid, tree, \n",
    "                 '../data/planet/india/geowiki/json_polys/geowiki_labeled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Blockchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10013/9517878 [00:09<2:22:33, 1111.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/india/GeneralBlockchain/json_polys/bbox_images26405.json\n",
      "method one count: 8788\n",
      "method two count: 15\n",
      "Number matched: 26405\n",
      "failed count 0\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../data/planet/india/GeneralBlockchain/'\n",
    "csv_file = os.path.join(base_dir, 'bbox_india_GB_v1.csv')\n",
    "\n",
    "shape_file = '../mount/data/GeneralBlockchain/campaign_results/india_fields_with_area.shp'\n",
    "\n",
    "if os.path.exists(os.path.join(base_dir, 'json_polys')) == False:\n",
    "    os.makedirs(os.path.join(base_dir, 'json_polys'))\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "grid, tree = read_csv(shape_file, df)\n",
    "\n",
    "dump_shp_to_json(shape_file, grid, tree, \n",
    "                 '../data/planet/india/GeneralBlockchain/json_polys/bbox_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Airbus images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9966/9517878 [00:04<1:09:28, 2280.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/general_blockchain/json_polys/bbox_Airbus_large9975.json\n",
      "method one count: 9898\n",
      "method two count: 68\n",
      "Number matched: 9975\n",
      "failed count 0\n"
     ]
    }
   ],
   "source": [
    "base_dir = '../data/general_blockchain/'\n",
    "csv_file = os.path.join(base_dir, 'bbox_india_GB_large_Airbus.csv')\n",
    "\n",
    "shape_file = '../mount/data/GeneralBlockchain/campaign_results/india_fields_with_area.shp'\n",
    "\n",
    "if os.path.exists(os.path.join(base_dir, 'json_polys')) == False:\n",
    "    os.makedirs(os.path.join(base_dir, 'json_polys'))\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "grid, tree = read_csv(shape_file, df)\n",
    "\n",
    "dump_shp_to_json(shape_file, grid, tree, \n",
    "                 '../data/general_blockchain/json_polys/bbox_Airbus_large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>min_lat</th>\n",
       "      <th>min_lon</th>\n",
       "      <th>max_lat</th>\n",
       "      <th>max_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.291001</td>\n",
       "      <td>73.093048</td>\n",
       "      <td>26.311001</td>\n",
       "      <td>73.115357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.707699</td>\n",
       "      <td>77.426401</td>\n",
       "      <td>25.727699</td>\n",
       "      <td>77.448599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.182688</td>\n",
       "      <td>76.592924</td>\n",
       "      <td>27.202688</td>\n",
       "      <td>76.615409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>27.466000</td>\n",
       "      <td>80.584531</td>\n",
       "      <td>27.486000</td>\n",
       "      <td>80.607074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21.107701</td>\n",
       "      <td>78.076782</td>\n",
       "      <td>21.127701</td>\n",
       "      <td>78.098221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id    min_lat    min_lon    max_lat    max_lon\n",
       "0         0  26.291001  73.093048  26.311001  73.115357\n",
       "1         1  25.707699  77.426401  25.727699  77.448599\n",
       "2         2  27.182688  76.592924  27.202688  76.615409\n",
       "3         3  27.466000  80.584531  27.486000  80.607074\n",
       "4         4  21.107701  78.076782  21.127701  78.098221"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Africa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Senegal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14543, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = '../data/planet/senegal/'\n",
    "csv_file = os.path.join(base_dir, 'bbox_tiles_all.csv')\n",
    "\n",
    "shape_file = '../mount/data/senegal_parcels/SenegalFields_03_26.shp'\n",
    "\n",
    "if os.path.exists(os.path.join(base_dir, 'json_polys')) == False:\n",
    "    os.makedirs(os.path.join(base_dir, 'json_polys'))\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2590/9517878 [00:01<1:17:12, 2053.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/senegal/json_polys/bbox_tiles_0_3293.json\n",
      "method one count: 2579\n",
      "method two count: 10\n",
      "Number matched: 3293\n",
      "failed count 1\n"
     ]
    }
   ],
   "source": [
    "increment = 20000\n",
    "    \n",
    "for start in np.arange(0, df.shape[0], increment):\n",
    "    end = start + increment\n",
    "    images_df = pd.read_csv(csv_file).iloc[start:end]\n",
    "\n",
    "    images_df['image_id'] = images_df['image_id'].astype(str).str.zfill(5)\n",
    "    grid, tree = read_csv(shape_file, images_df)\n",
    "    \n",
    "    dump_shp_to_json(shape_file, grid, tree, \n",
    "                     '../data/planet/senegal/json_polys/bbox_tiles_{}_'.format(int(start/increment)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ghana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18023, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = '../data/planet/ghana/udry/'\n",
    "csv_file = os.path.join(base_dir, 'bbox_tiles_all.csv')\n",
    "\n",
    "shape_file = '../mount/data/udry_parcels/udry_fields_2017.shp'\n",
    "\n",
    "if os.path.exists(os.path.join(base_dir, 'json_polys')) == False:\n",
    "    os.makedirs(os.path.join(base_dir, 'json_polys'))\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8938/9517878 [00:04<1:23:23, 1900.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/ghana/udry/json_polys/bbox_tiles_0_111334.json\n",
      "method one count: 8938\n",
      "method two count: 0\n",
      "Number matched: 11334\n",
      "failed count 0\n"
     ]
    }
   ],
   "source": [
    "increment = 20000\n",
    "    \n",
    "for start in np.arange(0, df.shape[0], increment):\n",
    "    end = start + increment\n",
    "    images_df = pd.read_csv(csv_file).iloc[start:end]\n",
    "\n",
    "    images_df['image_id'] = images_df['image_id'].astype(str).str.zfill(5)\n",
    "    grid, tree = read_csv(shape_file, images_df)\n",
    "    \n",
    "    dump_shp_to_json(shape_file, grid, tree, \n",
    "                     '../data/planet/ghana/udry/json_polys/bbox_tiles_{}_1'.format(\n",
    "                         int(start/increment)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Malawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2372, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = '../data/planet/malawi/'\n",
    "csv_file = os.path.join(base_dir, 'bbox_tiles_all.csv')\n",
    "\n",
    "shape_file = '../mount/data/malawi_parcels/malawi_WFP_fields_2018.shp'\n",
    "\n",
    "if os.path.exists(os.path.join(base_dir, 'json_polys')) == False:\n",
    "    os.makedirs(os.path.join(base_dir, 'json_polys'))\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 423/9517878 [00:00<1:16:26, 2074.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving json\n",
      "saved ../data/planet/malawi/json_polys/bbox_tiles_0_499.json\n",
      "method one count: 423\n",
      "method two count: 0\n",
      "Number matched: 499\n",
      "failed count 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "increment = 20000\n",
    "    \n",
    "for start in np.arange(0, df.shape[0], increment):\n",
    "    end = start + increment\n",
    "    images_df = pd.read_csv(csv_file).iloc[start:end]\n",
    "\n",
    "    images_df['image_id'] = images_df['image_id'].astype(str).str.zfill(5)\n",
    "    grid, tree = read_csv(shape_file, images_df)\n",
    "    \n",
    "    dump_shp_to_json(shape_file, grid, tree, \n",
    "                     '../data/planet/malawi/json_polys/bbox_tiles_{}_'.format(int(start/increment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_geopython)",
   "language": "python",
   "name": "conda_geopython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
